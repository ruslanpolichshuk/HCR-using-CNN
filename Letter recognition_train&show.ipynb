{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c1f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical  # Will be used to categorize an output layer neurons\n",
    "\n",
    "# Import all required layers types\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Load optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd01340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"latin_data.csv\") as file_name:\n",
    "    X_all_0 = np.loadtxt(file_name, delimiter=\",\")\n",
    "    \n",
    "X_all=X_all_0.reshape(X_all_0.shape[0], 28, 28, 1)\n",
    "X_all=X_all.astype('float32')\n",
    "\n",
    "with open(\"latin_label.csv\") as file_name:\n",
    "    Y_all_0 = np.loadtxt(file_name, delimiter=\",\")\n",
    "Y_all=to_categorical(Y_all_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27878eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbyclass=[493, 496, 508, 461, 500, 482, 509, 509, 476, 458, 460, 523, 547, 521, 465, 526, 484, 470, 519, 477, 475, 480, 465, 490, 545, 483]\n",
    "Trnumbyclass=[394, 397, 406, 369, 400, 386, 407, 407, 381, 366, 368, 418, 438, 417, 372, 421, 387, 376, 415, 382, 380, 384, 372, 392, 436, 386]\n",
    "\n",
    "currentidx=0\n",
    "tridx=[]\n",
    "tsidx=[];\n",
    "for i in range(26):\n",
    "    tridx=np.append(tridx,range(currentidx, currentidx+Trnumbyclass[i]))\n",
    "    tsidx=np.append(tsidx,range(currentidx+Trnumbyclass[i], currentidx+numbyclass[i]))\n",
    "    currentidx=currentidx+numbyclass[i]\n",
    "\n",
    "tridx=tridx.astype(int)   \n",
    "\n",
    "tsidx=tsidx.astype(int) \n",
    "\n",
    "\n",
    "Xtr=np.array([X_all[x] for x in tridx])\n",
    "Xts=np.array([X_all[x] for x in tsidx])\n",
    "Xtr_0=np.array([X_all_0[x] for x in tridx])\n",
    "Xts_0=np.array([X_all_0[x] for x in tsidx])\n",
    "Ytr=np.array([Y_all[x] for x in tridx])\n",
    "Yts=np.array([Y_all[x] for x in tsidx])\n",
    "Ytr_0=np.array([Y_all_0[x] for x in tridx])\n",
    "Yts_0=np.array([Y_all_0[x] for x in tsidx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a function to build CNN architecture according to the paper (case 1)\n",
    "def CNN_modelSetup(layers):\n",
    "  CNN_model = Sequential()\n",
    "\n",
    "  for l in layers:\n",
    "    if(l == 'conv1'):\n",
    "      CNN_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1))) #conv1\n",
    "    if(l == 'conv2'):\n",
    "      CNN_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform')) #conv2\n",
    "    if(l == 'pool'):\n",
    "      CNN_model.add(MaxPooling2D((2, 2))) #pool\n",
    "    if(l == 'dropout1'):\n",
    "      CNN_model.add(Dropout(0.25))\n",
    "    if(l == 'flatten'):\n",
    "      CNN_model.add(Flatten())\n",
    "    if(l == 'dense1'):\n",
    "      CNN_model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    if(l == 'dropout2'):\n",
    "      CNN_model.add(Dropout(0.5))\n",
    "    if(l == 'dense2'):\n",
    "      CNN_model.add(Dense(26, activation='softmax'))\n",
    "\t# compile model\n",
    "  opt = Adam(learning_rate=0.001)\n",
    "  # opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "  CNN_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return CNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = [\n",
    "        ['conv1', 'conv2', 'pool', 'dropout1', 'flatten', 'dense1', 'dropout2', 'dense2'],\n",
    "        ['conv1', 'pool', 'conv2', 'pool', 'dropout1', 'flatten', 'dense1', 'dropout2', 'dense2'],\n",
    "        ['conv1', 'conv2', 'pool', 'flatten', 'dense1', 'dense2'],\n",
    "        ['conv1', 'pool', 'conv2', 'pool', 'flatten', 'dense1', 'dense2'],\n",
    "        ['conv1', 'conv2', 'pool', 'flatten', 'dense1', 'dropout2', 'dense2'],\n",
    "        ['conv1', 'pool', 'conv2', 'pool', 'flatten', 'dense1', 'dropout2', 'dense2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[0])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case0.h5\")\n",
    "\n",
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[1])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case1.h5\")\n",
    "\n",
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[2])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case2.h5\")\n",
    "\n",
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[3])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case3.h5\")\n",
    "\n",
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[4])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case4.h5\")\n",
    "\n",
    "#Model training\n",
    "CNN_mod = CNN_modelSetup(case[5])\n",
    "CNN_mod.fit(Xtr, Ytr, validation_data=(Xts, Yts), epochs=15, batch_size=50, verbose=2)\n",
    "scores = CNN_mod.evaluate(Xts, Yts, verbose=0)\n",
    "CNN_mod.save(\"LetterRecognition_case5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3851aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictions = CNN_mod.predict(Xts)\n",
    "classes_x=np.argmax(predictions,axis=1)\n",
    "classes_letter=['A','B','C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "# Compare predicted and actual classes\n",
    "rndmind = np.random.choice(range(len(Xts)), 5)\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "for i, idx in enumerate(rndmind):\n",
    "    img = Xts[idx] \n",
    "    img=img.astype('float32')*255.0\n",
    "    ax = fig.add_subplot(1, 5, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'predicted = ' + classes_letter[classes_x[idx]], fontsize=22, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'actual = ' + classes_letter[Yts_0[idx].astype(int)], fontsize=22, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f95e442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI for letter recognition. Source: https://github.com/shafinhasnat/English-digit-recognition-GUI-with-tkinter\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "import PIL.Image as Img\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "\n",
    "classes_letter=['A','B','C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "width = 800\n",
    "height = 300\n",
    "center = height//2\n",
    "white = (255, 255, 255)\n",
    "green = (0,128,0)\n",
    "\n",
    "modelCNN=tf.keras.models.load_model('LetterRecognition_case4.h5') # Load our model\n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 10), (event.y - 10)\n",
    "    x2, y2 = (event.x + 10), (event.y + 10)\n",
    "    cv.create_oval(x1, y1, x2, y2, fill=\"black\",width=10)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=10)\n",
    "    \n",
    "def model():\n",
    "    filename = \"./image.png\"\n",
    "    image1.save(filename)\n",
    "    nchar=segmentation(filename)\n",
    "    txt.insert(tk.INSERT, \"Prediction: \")\n",
    "    for i in range(nchar):\n",
    "        pred=testing(i+1)\n",
    "        txt.insert(tk.INSERT,\"{}\".format(classes_letter[pred[0]]))\n",
    "    \n",
    "def clear():\n",
    "    cv.delete('all')\n",
    "    draw.rectangle((0, 0, 5000, 5000), fill=(255, 255, 255, 0))\n",
    "    txt.delete('1.0', END)\n",
    "    import os\n",
    "    filename = \"./image.png\"\n",
    "    nchar=segmentation(filename)\n",
    "    for i in range(nchar):\n",
    "        os.remove('./char_' +str(i+1)+'.png')\n",
    "    \n",
    "def testing(charnum):\n",
    "    img=cv2.imread('char_' +str(charnum)+'.png',0)\n",
    "    img=cv2.bitwise_not(img)\n",
    "    #cv2.imshow('img',img)\n",
    "    img=cv2.resize(img,(28,28))\n",
    "    img=img.reshape(1,28,28,1)\n",
    "    img=img.astype('float32')\n",
    "    img=img/255.0 \n",
    "    pred=modelCNN.predict(img)\n",
    "    classes_x=np.argmax(pred,axis=1)\n",
    "    \n",
    "    return classes_x\n",
    "\n",
    "def segmentation(file):\n",
    "    #file = \"./image.png\"\n",
    "    img = cv2.imread(file)\n",
    "    h, w, _ = img.shape\n",
    "    boxes = pytesseract.image_to_boxes(img)\n",
    "    charcoordintates=boxes.splitlines()\n",
    "    nchar=len(charcoordintates)\n",
    "    k=1;\n",
    "    for b in boxes.splitlines():\n",
    "        b = b.split(' ')\n",
    "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "        fp = open(file,\"rb\")\n",
    "        imageObject = PIL.Image.open(fp)\n",
    "        #imageObject = Image.open('image.png')\n",
    "        cropped = imageObject.crop((int(b[1]), \n",
    "                                    h-int(b[4]),\n",
    "                                    int(b[3]),\n",
    "                                    h-int(b[2]),\n",
    "                                   ))\n",
    "        card = Img.new(\"RGBA\", (300, 300), (255, 255, 255))\n",
    "        img2 = cropped.convert(\"RGBA\")\n",
    "        x, y = img2.size\n",
    "        ov=75\n",
    "        card.paste(img2, (ov, ov, x+ov, y+ov), img2)\n",
    "        card.save('char_' +str(k)+'.png', 'PNG')\n",
    "        k=k+1\n",
    "    return nchar\n",
    "    \n",
    "root = Tk()\n",
    "##root.geometry('1000x500') \n",
    "\n",
    "root.resizable(0,0)\n",
    "cv = Canvas(root, width=width, height=height, bg='white')\n",
    "cv.pack()\n",
    "\n",
    "# PIL create an empty image and draw object to draw on\n",
    "# memory only, not visible\n",
    "image1 = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "draw = ImageDraw.Draw(image1)\n",
    "\n",
    "txt=tk.Text(root,bd=3,exportselection=0,bg='WHITE',font='Helvetica',\n",
    "            padx=10,pady=10,height=5,width=20)\n",
    "\n",
    "cv.pack(expand=YES, fill=BOTH)\n",
    "cv.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "##button=Button(text=\"save\",command=save)\n",
    "btnModel=Button(text=\"Predict\",command=model)\n",
    "btnClear=Button(text=\"clear\",command=clear)\n",
    "##button.pack()\n",
    "btnModel.pack()\n",
    "btnClear.pack()\n",
    "txt.pack()\n",
    "root.title('Letter recognition')\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e92c5186-c97f-46fb-ad70-f1a75b4a31cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd806bda-55ef-4ca8-bf53-1502770099c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d46fc-37bf-4b5c-a633-746f4ecea64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
